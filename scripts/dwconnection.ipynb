{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVBNzdSotmAf",
    "outputId": "c84a7394-b87e-49d1-d40f-b67795432b2a"
   },
   "outputs": [],
   "source": [
    "#pip install snowflake-connector-python\n",
    "#pip install snowflake-sqlalchemy\n",
    "\n",
    "#install those if not installed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XnCvNeVksxXF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from google.cloud import storage\n",
    "from math import ceil\n",
    "import datetime\n",
    "import calendar\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.connector import connect\n",
    "from google.cloud import storage\n",
    "from snowflake.connector import connect\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects import registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4etNw1s1tBKj",
    "outputId": "74f8dd4a-778c-44d1-aa1f-454bf9277ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.16.0\n"
     ]
    }
   ],
   "source": [
    "# Connect to snowflake \n",
    "# Read credentials from config file\n",
    "with open('config_dw.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "snowflake_config = config['snowflake']\n",
    "\n",
    "# Your Snowflake database credentials\n",
    "account_name = snowflake_config['account_name']\n",
    "user = snowflake_config['user']\n",
    "password = snowflake_config['password']\n",
    "database = snowflake_config['database']\n",
    "schema = snowflake_config['schema']\n",
    "\n",
    "# Establish a connection to Snowflake\n",
    "conn = connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account_name,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "registry.register('snowflake', 'snowflake.sqlalchemy', 'dialect')\n",
    "\n",
    "# Create a SQLAlchemy engine for Snowflake\n",
    "snowflake_engine = create_engine(f'snowflake://{user}:{password}@{account_name}/{database}/{schema}')\n",
    "connection = snowflake_engine.connect()\n",
    "results = connection.execute('select current_version()').fetchone()\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FwmpNtB3Zhy",
    "outputId": "5765c42b-fc50-44cc-f94c-90aa6d57875e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600:387:f:7810::c"
     ]
    }
   ],
   "source": [
    "!curl ipecho.net/plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4uWbC5d4sxXG",
    "outputId": "a17cd303-15cb-4be0-e3dd-79eee8c052c1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Recreate the iterator blob_list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m blob_list \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mlist_blobs()\n\u001b[1;32m      4\u001b[0m \u001b[39m# Initialize a counter for the number of processed files\u001b[39;00m\n\u001b[1;32m      5\u001b[0m file_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bucket' is not defined"
     ]
    }
   ],
   "source": [
    "# Recreate the iterator blob_list\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Initialize a counter for the number of processed files\n",
    "file_count = 0\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    # Check if the blob is a file (not a directory) \n",
    "    if '.' in blob_name:\n",
    "        # Check if the file is in the \"Sales/NY\" directory\n",
    "        if blob_name.startswith(\"SALES/NY/\") or blob_name == \"SALES/NY\":\n",
    "            # Increment the file count\n",
    "            file_count += 1\n",
    "            \n",
    "            # Check if we have processed 50 files\n",
    "            if file_count > 50:\n",
    "                print(\"Reached 50 files, stopping processing.\")\n",
    "                break  # Stop processing further files\n",
    "                \n",
    "            # Get the blob\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Download the blob content\n",
    "            blob_content = blob.download_as_string()\n",
    "\n",
    "            # Convert blob content to DataFrame\n",
    "            df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "            # Display the shape of the DataFrame\n",
    "            print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "\n",
    "            # Store the DataFrame into Snowflake\n",
    "            table_name = blob_name.split('/')[-1].split('.')[0]  # Extract table name from blob name\n",
    "            df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n",
    "            print(f\"DataFrame stored in Snowflake table: {table_name}\")\n",
    "        else:\n",
    "            print(\"Blob is not in the 'Sales/NY' directory, skipping...\")\n",
    "    else:\n",
    "        print(\"Blob is not a file, skipping...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ebhZ7Iv5sxXH",
    "outputId": "9c7e50d5-dc1e-4e5d-84ac-27d2816a56ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing blob: 0.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: MIT_livingwage_calculation.csv\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: MIT_typicalannualsalaries.csv\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: MIT_typicalexpenses.csv\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: NYS crime data.csv\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/0.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/1000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/10000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/100000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/101000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/102000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/103000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/104000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/105000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/106000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/107000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/108000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/109000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/11000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/110000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/111000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/112000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/113000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/114000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/115000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/116000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/117000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/118000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/119000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/12000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/120000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/121000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/122000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/123000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/124000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/125000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/126000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/127000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/128000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/129000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/13000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/130000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/131000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/132000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/133000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/134000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/135000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/136000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/137000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/138000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/139000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/14000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/140000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/141000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/142000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/143000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/144000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/145000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/146000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/147000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/148000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/149000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/15000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/150000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/151000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/152000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/153000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/154000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/155000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/156000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/157000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/158000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/159000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/16000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/160000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/161000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/162000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/163000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/164000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/165000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/166000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/167000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/17000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/18000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/19000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/2000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/20000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/21000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/22000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/23000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/24000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/25000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/26000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/27000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/28000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/29000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/3000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/30000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/31000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/32000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/33000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/34000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/35000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/36000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/37000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/38000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/39000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/4000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/40000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/41000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/42000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/43000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/44000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/45000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/46000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/47000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/48000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/49000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/5000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/50000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/51000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/52000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/53000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/54000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/55000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/56000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/57000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/58000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/59000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/6000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/60000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/61000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/62000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/63000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/64000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/65000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/66000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/67000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/68000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/69000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/7000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/70000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/71000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/72000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/73000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/74000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/75000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/76000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/77000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/78000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/79000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/8000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/80000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/81000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/82000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/83000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/84000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/85000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/86000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/87000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/88000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/89000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/9000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/90000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/91000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/92000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/93000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/94000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/95000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/96000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/97000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/98000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SALES/NY/99000.json\n",
      "Blob is not a file, skipping...\n",
      "Processing blob: SCHOOL_DATA.csv\n",
      "Shape of SCHOOL_DATA.csv: (194735, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/y4jkcjwx1zsdr2dqg2zg998r0000gn/T/ipykernel_1827/1925320818.py:25: UserWarning: The provided table name 'SCHOOL_DATA' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame stored in Snowflake table: SCHOOL_DATA\n"
     ]
    }
   ],
   "source": [
    "# Recreate the iterator blob_list\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    #CHANGE THIS CODE TO UPDATE ONLT THE NEEDED FILES (DO NOT UPDATE ALL AGAIN SINCE WE ALREADY HAVE SOME IN SNOWFALKE)\n",
    "    # Check if the blob is a file (not a directory) \n",
    "    if '.' in blob_name in blob_name:\n",
    "        # Get the blob\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download the blob content\n",
    "        blob_content = blob.download_as_string()\n",
    "\n",
    "        # Convert blob content to DataFrame\n",
    "        df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "        # Display the shape of the DataFrame\n",
    "        print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "\n",
    "        # Store the DataFrame into Snowflake\n",
    "        table_name = blob_name.split('.')[0]  # Extract table name from blob name\n",
    "        df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n",
    "        print(f\"DataFrame stored in Snowflake table: {table_name}\")\n",
    "    else:\n",
    "        print(\"Blob is not a file, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing blob: 0.json\n",
      "Blob is not in the 'Sales/NY' directory, skipping...\n",
      "Processing blob: MIT_livingwage_calculation.csv\n",
      "Blob is not in the 'Sales/NY' directory, skipping...\n",
      "Processing blob: MIT_typicalannualsalaries.csv\n",
      "Blob is not in the 'Sales/NY' directory, skipping...\n",
      "Processing blob: MIT_typicalexpenses.csv\n",
      "Blob is not in the 'Sales/NY' directory, skipping...\n",
      "Processing blob: NYS crime data.csv\n",
      "Blob is not in the 'Sales/NY' directory, skipping...\n",
      "Processing blob: SALES/NY/0.json\n",
      "Processing blob: SALES/NY/1000.json\n",
      "Processing blob: SALES/NY/10000.json\n",
      "Processing blob: SALES/NY/100000.json\n",
      "Processing blob: SALES/NY/101000.json\n",
      "Processing blob: SALES/NY/102000.json\n",
      "Processing blob: SALES/NY/103000.json\n",
      "Processing blob: SALES/NY/104000.json\n",
      "Processing blob: SALES/NY/105000.json\n",
      "Processing blob: SALES/NY/106000.json\n",
      "Processing blob: SALES/NY/107000.json\n",
      "Processing blob: SALES/NY/108000.json\n",
      "Processing blob: SALES/NY/109000.json\n",
      "Shape of SALES/NY/109000.json: (0, 43454)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[39m# Store the DataFrame into Snowflake\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     table_name \u001b[39m=\u001b[39m blob_name\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]  \u001b[39m# Extract table name from blob name\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     df\u001b[39m.\u001b[39;49mto_sql(table_name, con\u001b[39m=\u001b[39;49msnowflake_engine, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     49\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame stored in Snowflake table: \u001b[39m\u001b[39m{\u001b[39;00mtable_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/core/generic.py:2878\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2714\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2715\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2874\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2875\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2876\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[0;32m-> 2878\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m   2879\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2880\u001b[0m     name,\n\u001b[1;32m   2881\u001b[0m     con,\n\u001b[1;32m   2882\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   2883\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   2884\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2885\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   2886\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   2887\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2888\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   2889\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/sql.py:767\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    763\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[39m=\u001b[39mschema, need_transaction\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 767\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m    768\u001b[0m         frame,\n\u001b[1;32m    769\u001b[0m         name,\n\u001b[1;32m    770\u001b[0m         if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m    771\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    772\u001b[0m         index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m    773\u001b[0m         schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    774\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    775\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    776\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    777\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    778\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m    779\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/sql.py:1908\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1904\u001b[0m \u001b[39m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m   1905\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1906\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m-> 1908\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprep_table(\n\u001b[1;32m   1909\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1910\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1911\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   1912\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1913\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   1914\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1915\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1916\u001b[0m )\n\u001b[1;32m   1918\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39minsert_records(\n\u001b[1;32m   1919\u001b[0m     table\u001b[39m=\u001b[39mtable,\n\u001b[1;32m   1920\u001b[0m     con\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[1;32m   1928\u001b[0m )\n\u001b[1;32m   1930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/sql.py:1802\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1800\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe type of \u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m is not a SQLAlchemy type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1802\u001b[0m table \u001b[39m=\u001b[39m SQLTable(\n\u001b[1;32m   1803\u001b[0m     name,\n\u001b[1;32m   1804\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1805\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1806\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1807\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   1808\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   1809\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1810\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1811\u001b[0m )\n\u001b[1;32m   1812\u001b[0m table\u001b[39m.\u001b[39mcreate()\n\u001b[1;32m   1813\u001b[0m \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/sql.py:878\u001b[0m, in \u001b[0;36mSQLTable.__init__\u001b[0;34m(self, name, pandas_sql_engine, frame, index, if_exists, prefix, index_label, schema, keys, dtype)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m frame \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# We want to initialize based on a dataframe\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_table_setup()\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# no data provided, read-only mode\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpd_sql\u001b[39m.\u001b[39mget_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/sql.py:1187\u001b[0m, in \u001b[0;36mSQLTable._create_table_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[39m# At this point, attach to new metadata, only attach to self.meta\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m \u001b[39m# once table is created.\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m meta \u001b[39m=\u001b[39m MetaData()\n\u001b[0;32m-> 1187\u001b[0m \u001b[39mreturn\u001b[39;00m Table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, meta, \u001b[39m*\u001b[39;49mcolumns, schema\u001b[39m=\u001b[39;49mschema)\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/util/deprecations.py:375\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    369\u001b[0m         _warn_with_version(\n\u001b[1;32m    370\u001b[0m             messages[m],\n\u001b[1;32m    371\u001b[0m             versions[m],\n\u001b[1;32m    372\u001b[0m             version_warnings[m],\n\u001b[1;32m    373\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m    374\u001b[0m         )\n\u001b[0;32m--> 375\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/sql/schema.py:614\u001b[0m, in \u001b[0;36mTable.__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    612\u001b[0m metadata\u001b[39m.\u001b[39m_add_table(name, schema, table)\n\u001b[1;32m    613\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 614\u001b[0m     table\u001b[39m.\u001b[39;49m_init(name, metadata, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    615\u001b[0m     table\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_parent_attach(table, metadata)\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/sql/schema.py:700\u001b[0m, in \u001b[0;36mTable._init\u001b[0;34m(self, name, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autoload(\n\u001b[1;32m    690\u001b[0m         metadata,\n\u001b[1;32m    691\u001b[0m         autoload_with,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m         resolve_fks\u001b[39m=\u001b[39mresolve_fks,\n\u001b[1;32m    695\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[39m# initialize all the column, etc. objects.  done after reflection to\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39m# allow user-overrides\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_items(\n\u001b[1;32m    701\u001b[0m     \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    702\u001b[0m     allow_replacements\u001b[39m=\u001b[39;49mextend_existing \u001b[39mor\u001b[39;49;00m keep_existing \u001b[39mor\u001b[39;49;00m autoload\n\u001b[1;32m    703\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/sql/schema.py:144\u001b[0m, in \u001b[0;36mSchemaItem._init_items\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    136\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m    137\u001b[0m         exc\u001b[39m.\u001b[39mArgumentError(\n\u001b[1;32m    138\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSchemaItem\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object, such as a \u001b[39m\u001b[39m'\u001b[39m\u001b[39mColumn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         replace_context\u001b[39m=\u001b[39merr,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     spwd(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/sql/base.py:1047\u001b[0m, in \u001b[0;36mSchemaEventTarget._set_parent_with_dispatch\u001b[0;34m(self, parent, **kw)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_parent_with_dispatch\u001b[39m(\u001b[39mself\u001b[39m, parent, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m   1046\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mbefore_parent_attach(\u001b[39mself\u001b[39m, parent)\n\u001b[0;32m-> 1047\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parent(parent, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m   1048\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_parent_attach(\u001b[39mself\u001b[39m, parent)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/sql/schema.py:1923\u001b[0m, in \u001b[0;36mColumn._set_parent\u001b[0;34m(self, table, allow_replacements)\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[39mif\u001b[39;00m fk\u001b[39m.\u001b[39mconstraint \u001b[39min\u001b[39;00m table\u001b[39m.\u001b[39mconstraints:\n\u001b[1;32m   1918\u001b[0m                 \u001b[39m# this might have been removed\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m                 \u001b[39m# already, if it's a composite constraint\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m                 \u001b[39m# and more than one col being replaced\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m                 table\u001b[39m.\u001b[39mconstraints\u001b[39m.\u001b[39mremove(fk\u001b[39m.\u001b[39mconstraint)\n\u001b[0;32m-> 1923\u001b[0m table\u001b[39m.\u001b[39;49m_columns\u001b[39m.\u001b[39;49mreplace(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1925\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtable \u001b[39m=\u001b[39m table\n\u001b[1;32m   1927\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprimary_key:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sqlalchemy/sql/base.py:1577\u001b[0m, in \u001b[0;36mDedupeColumnCollection.replace\u001b[0;34m(self, column)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             new_cols\u001b[39m.\u001b[39mappend((column\u001b[39m.\u001b[39mkey, column))\n\u001b[1;32m   1576\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1577\u001b[0m         new_cols\u001b[39m.\u001b[39;49mappend((k, col))\n\u001b[1;32m   1579\u001b[0m \u001b[39mif\u001b[39;00m remove_col:\n\u001b[1;32m   1580\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_colset\u001b[39m.\u001b[39mdifference_update(remove_col)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Recreate the iterator blob_list\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Initialize a counter for the number of processed files\n",
    "file_count = 0\n",
    "\n",
    "# Flag to indicate if we have encountered the starting point\n",
    "start_processing = False\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    # Check if the blob is a file (not a directory) \n",
    "    if '.' in blob_name:\n",
    "        # Check if the file is in the \"Sales/NY\" directory\n",
    "        if blob_name.startswith(\"SALES/NY/\") or blob_name == \"SALES/NY\":\n",
    "            # Increment the file count\n",
    "            file_count += 1\n",
    "\n",
    "            # Check if we have reached the starting point\n",
    "            if not start_processing:\n",
    "                if file_count == 13:\n",
    "                    start_processing = True\n",
    "                else:\n",
    "                    continue  # Skip until we reach the starting point\n",
    "\n",
    "            # Check if we have processed 50 files\n",
    "            if file_count > 50:\n",
    "                print(\"Reached 50 files, stopping processing.\")\n",
    "                break  # Stop processing further files\n",
    "\n",
    "            # Get the blob\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Download the blob content\n",
    "            blob_content = blob.download_as_string()\n",
    "\n",
    "            # Convert blob content to DataFrame\n",
    "            df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "            # Display the shape of the DataFrame\n",
    "            print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "\n",
    "            # Store the DataFrame into Snowflake\n",
    "            table_name = blob_name.split('/')[-1].split('.')[0]  # Extract table name from blob name\n",
    "            df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n",
    "            print(f\"DataFrame stored in Snowflake table: {table_name}\")\n",
    "        else:\n",
    "            print(\"Blob is not in the 'Sales/NY' directory, skipping...\")\n",
    "    else:\n",
    "        print(\"Blob is not a file, skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Recreate the iterator blob_list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m blob_list \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mlist_blobs()\n\u001b[1;32m      4\u001b[0m \u001b[39m# Initialize a counter for the number of processed files\u001b[39;00m\n\u001b[1;32m      5\u001b[0m file_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bucket' is not defined"
     ]
    }
   ],
   "source": [
    "# Recreate the iterator blob_list\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Initialize a counter for the number of processed files\n",
    "file_count = 0\n",
    "\n",
    "# Flag to indicate if we have encountered the starting point\n",
    "start_processing = False\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    # Check if the blob is a file (not a directory) \n",
    "    if '.' in blob_name:\n",
    "        # Check if the file is in the \"Sales/NY\" directory\n",
    "        if blob_name.startswith(\"SALES/NY/\") or blob_name == \"SALES/NY\":\n",
    "            # Increment the file count\n",
    "            file_count += 1\n",
    "\n",
    "            # Check if we have reached the starting point\n",
    "            if not start_processing:\n",
    "                if file_count == 13:\n",
    "                    start_processing = True\n",
    "                else:\n",
    "                    continue  # Skip until we reach the starting point\n",
    "\n",
    "            # Check if we have processed 50 files\n",
    "            if file_count > 50:\n",
    "                print(\"Reached 50 files, stopping processing.\")\n",
    "                break  # Stop processing further files\n",
    "\n",
    "            # Get the blob\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Download the blob content\n",
    "            blob_content = blob.download_as_string()\n",
    "\n",
    "            # Convert blob content to DataFrame\n",
    "            df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "            # Display the shape of the DataFrame\n",
    "            print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "\n",
    "            # Store the DataFrame into Snowflake\n",
    "            table_name = blob_name.split('/')[-1].split('.')[0]  # Extract table name from blob name\n",
    "            df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n",
    "            print(f\"DataFrame stored in Snowflake table: {table_name}\")\n",
    "        else:\n",
    "            print(\"Blob is not in the 'Sales/NY' directory, skipping...\")\n",
    "    else:\n",
    "        print(\"Blob is not a file, skipping...\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
