{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XnCvNeVksxXF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from google.cloud import storage\n",
    "from math import ceil\n",
    "import datetime\n",
    "import calendar\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.connector import connect\n",
    "from snowflake.connector import connect\n",
    "from sqlalchemy.dialects import registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4etNw1s1tBKj",
    "outputId": "74f8dd4a-778c-44d1-aa1f-454bf9277ecf"
   },
   "outputs": [],
   "source": [
    "# Connect to snowflake \n",
    "# Read credentials from config file\n",
    "with open('config_dw.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "snowflake_config = config['snowflake']\n",
    "\n",
    "# Your Snowflake database credentials\n",
    "account_name = snowflake_config['account_name']\n",
    "user = snowflake_config['user']\n",
    "password = snowflake_config['password']\n",
    "database = snowflake_config['database']\n",
    "schema = snowflake_config['schema']\n",
    "\n",
    "# Establish a connection to Snowflake\n",
    "conn = connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account_name,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "registry.register('snowflake', 'snowflake.sqlalchemy', 'dialect')\n",
    "\n",
    "# Create a SQLAlchemy engine for Snowflake\n",
    "snowflake_engine = create_engine(f'snowflake://{user}:{password}@{account_name}/{database}/{schema}')\n",
    "connection = snowflake_engine.connect()\n",
    "results = connection.execute('select current_version()').fetchone()\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl ipecho.net/plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration data\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "# Authenticate with Google Cloud Storage using the service account JSON\n",
    "storage_client = storage.Client.from_service_account_info(config_data)\n",
    "\n",
    "# Google Cloud Storage Configuration\n",
    "BUCKET_NAME = \"housingproject_cis9440\"\n",
    "\n",
    "# Get the bucket\n",
    "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
    "\n",
    "# List all blobs in the specified container\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    # Check if the blob is a file (not a directory)\n",
    "    if '.' in blob_name:\n",
    "        # Get the blob\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download the blob content\n",
    "        blob_content = blob.download_as_string()\n",
    "\n",
    "        # Convert blob content to DataFrame\n",
    "        df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "        # Display the shape of the DataFrame\n",
    "        print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "    else:\n",
    "        print(\"Blob is a directory, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebhZ7Iv5sxXH",
    "outputId": "9c7e50d5-dc1e-4e5d-84ac-27d2816a56ac"
   },
   "outputs": [],
   "source": [
    "# Recreate the iterator blob_list\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    # Check if the blob is a file (not a directory) \n",
    "    if '.' in blob_name in blob_name:\n",
    "        # Get the blob\n",
    "        blob = bucket.blob(blob_name)\n",
    "\n",
    "        # Download the blob content\n",
    "        blob_content = blob.download_as_string()\n",
    "\n",
    "        # Convert blob content to DataFrame\n",
    "        df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "        # Display the shape of the DataFrame\n",
    "        print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "\n",
    "        # Store the DataFrame into Snowflake\n",
    "        table_name = blob_name.split('.')[0]  # Extract table name from blob name\n",
    "        df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n",
    "        print(f\"DataFrame stored in Snowflake table: {table_name}\")\n",
    "    else:\n",
    "        print(\"Blob is not a file, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the iterator blob_list\n",
    "blob_list = bucket.list_blobs()\n",
    "\n",
    "# Initialize a counter for the number of processed files\n",
    "file_count = 0\n",
    "\n",
    "# Flag to indicate if we have encountered the starting point\n",
    "start_processing = False\n",
    "\n",
    "# Iterate over each blob\n",
    "for blob in blob_list:\n",
    "    blob_name = blob.name\n",
    "    print(f\"Processing blob: {blob_name}\")\n",
    "\n",
    "    # Check if the blob is a file (not a directory) \n",
    "    if '.' in blob_name:\n",
    "        # Check if the file is in the \"Sales/NY\" directory\n",
    "        if blob_name.startswith(\"SALES/NY/\") or blob_name == \"SALES/NY\":\n",
    "            # Increment the file count\n",
    "            file_count += 1\n",
    "\n",
    "            # Check if we have reached the starting point\n",
    "            if not start_processing:\n",
    "                if file_count == 13:\n",
    "                    start_processing = True\n",
    "                else:\n",
    "                    continue  # Skip until we reach the starting point\n",
    "\n",
    "            # Check if we have processed 50 files\n",
    "            if file_count > 50:\n",
    "                print(\"Reached 50 files, stopping processing.\")\n",
    "                break  # Stop processing further files\n",
    "\n",
    "            # Get the blob\n",
    "            blob = bucket.blob(blob_name)\n",
    "\n",
    "            # Download the blob content\n",
    "            blob_content = blob.download_as_string()\n",
    "\n",
    "            # Convert blob content to DataFrame\n",
    "            df = pd.read_csv(StringIO(blob_content.decode('utf-8')))\n",
    "\n",
    "            # Display the shape of the DataFrame\n",
    "            print(f\"Shape of {blob_name}: {df.shape}\")\n",
    "\n",
    "            # Store the DataFrame into Snowflake\n",
    "            table_name = blob_name.split('/')[-1].split('.')[0]  # Extract table name from blob name\n",
    "            df.to_sql(table_name, con=snowflake_engine, if_exists='append', index=False)\n",
    "            print(f\"DataFrame stored in Snowflake table: {table_name}\")\n",
    "        else:\n",
    "            print(\"Blob is not in the 'Sales/NY' directory, skipping...\")\n",
    "    else:\n",
    "        print(\"Blob is not a file, skipping...\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
